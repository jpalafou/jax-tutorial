{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Jax/Numpy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "\n",
    "try:\n",
    "    import rich\n",
    "except ModuleNotFoundError:\n",
    "    print(\"rich not found, install it with pip install rich\")\n",
    "    !pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.array([1.0, 2.0, 3.0])\n",
    "\n",
    "print(f\"{x=}\")\n",
    "print(f\"{type(x)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most numpy functions are available with the `jax.numpy` namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.square(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `onp` to convert Jax arrays to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onp.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(onp.square(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike NumPy, JAX arrays are immutable,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_onp = onp.arange(0.0, 10.0)\n",
    "x_onp[:5] = -1.0\n",
    "x_onp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jnp = jnp.arange(0.0, 10.0)\n",
    "x_jnp[:5] = -1.0\n",
    "x_jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meaning any modification requires creating a new array rather than altering the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jnp = jnp.arange(0.0, 10.0)\n",
    "x_jnp = x_jnp.at[:5].set(-1.0)\n",
    "x_jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Jax as a tool for computing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function\n",
    "\n",
    "$f(x, y, z) = \\sin(x) + e^y + \\sqrt{z}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    x, y, z = X\n",
    "    return jnp.sin(x) + jnp.exp(y) + jnp.sqrt(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has partial derivatives\n",
    "\n",
    "$\\frac{\\partial f}{\\partial x} = \\cos(x)$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = e^y$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial z} = \\frac{1}{2\\sqrt{z}},$\n",
    "\n",
    "which can be computed exactly with `jax.grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdX = grad(f)\n",
    "\n",
    "dfdX(jnp.array([0.0, 0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a parameter $h$:\n",
    "\n",
    "$f(x, y, z; h) = \\sin(x-h) + e^{y-h} + \\sqrt{z-h}.$\n",
    "\n",
    "This gives a new partial derivative\n",
    "\n",
    "$\\frac{\\partial f}{\\partial h} = -\\cos(x-h) - e^{y-h} - \\frac{1}{2\\sqrt{z-h}}.$\n",
    "\n",
    "We can use automatic differentiation to compute $\\frac{\\partial f}{\\partial h}$ by specifying `argnums`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X, h):\n",
    "    x, y, z = X\n",
    "    return jnp.sin(x - h) + jnp.exp(y - h) + jnp.sqrt(z - h)\n",
    "\n",
    "\n",
    "grad(f, argnums=1)(jnp.array([0.0, 0.0, 0.25]), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's talk Jacobians and Hessians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jacobian, hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a vector-valued function\n",
    "\n",
    "$$\n",
    "\\vec{f}(u, v) =\n",
    "\\left[\\begin{array}{c} \n",
    "f_1(u,v)\\\\\n",
    "f_2(u,v)\n",
    "\\end{array}\\right]=\n",
    "\\left[\\begin{array}{c} \n",
    "e^u \\cos(v)\\\\\n",
    "e^u \\sin(v)\n",
    "\\end{array}\\right].\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fvec(X):\n",
    "    u, v = X\n",
    "    return jnp.array([jnp.exp(u) * jnp.cos(v), jnp.exp(u) * jnp.sin(v)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian of $\\vec{f}$ is written\n",
    "\n",
    "$$\n",
    "\\mathbf{J}_{\\vec{f}}=\n",
    "\\left[\\begin{array}{cc} \n",
    "\\partial f_1 / \\partial u & \\partial f_1 / \\partial v \\\\\n",
    "\\partial f_2 / \\partial u & \\partial f_2 / \\partial v\n",
    "\\end{array}\\right]=\n",
    "\\left[\\begin{array}{cc} \n",
    "e^u \\cos(v) & -e^u \\sin(v)\\\\\n",
    "e^u \\sin(v) & e^u \\cos(v)\n",
    "\\end{array}\\right]\n",
    "$$ \n",
    "\n",
    "and can be exactly computed with `jax.jacobian`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjac = jacobian(fvec)\n",
    "fjac(jnp.array([0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `jax.jacobian` is an alias for `jax.jacrev`, which computes gradients using reverse-mode automatic differentiation. In contrast, `jax.jacfwd` performs forward-mode differentiation. Reverse-mode (`jax.jacrev`) is more efficient for wide matrices, while forward-mode (`jax.jacfwd`) is better suited for tall matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hessian of $\\vec{f}$,\n",
    "$$\n",
    "\\mathbf{H}_{\\vec{f}}=\n",
    "\\left[\n",
    "\\left[\\begin{array}{cc} \n",
    "\\partial^2 f_1 / \\partial u^2 & \\partial^2 f_1 / \\partial u \\partial v\\\\\n",
    "\\partial^2 f_1 / \\partial v \\partial u & \\partial^2 f_1 / \\partial v^2\n",
    "\\end{array}\\right],\n",
    "\\left[\\begin{array}{cc} \n",
    "\\partial^2 f_2 / \\partial u^2 & \\partial^2 f_2 / \\partial u \\partial v\\\\\n",
    "\\partial^2 f_2 / \\partial v \\partial u & \\partial^2 f_2 / \\partial v^2\n",
    "\\end{array}\\right]\n",
    "\\right]=\n",
    "\\left[\n",
    "\\left[\\begin{array}{cc} \n",
    "e^u \\cos(v) & -e^u \\sin(v)\\\\\n",
    "-e^u \\sin(v) & -e^u \\cos(v)\n",
    "\\end{array}\\right],\n",
    "\\left[\\begin{array}{cc} \n",
    "e^u \\sin(v) & e^u \\cos(v)\\\\\n",
    "e^u \\cos(v) & -e^u \\sin(v)\n",
    "\\end{array}\\right]\n",
    "\\right],\n",
    "$$\n",
    "\n",
    "can be computed exactly with `jax.hessian`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhes = hessian(fvec)\n",
    "fhes(jnp.array([0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Banjamin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Matt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what devices we have available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can attach an array to a device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = jnp.arange(32.0).reshape(4, 8)\n",
    "arr.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a cool tool to visualise the partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.debug.visualize_array_sharding(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.sharding import PartitionSpec as P\n",
    "\n",
    "n = jax.device_count()\n",
    "print(f\"Sharding overs {n} devices\")\n",
    "\n",
    "mesh = jax.make_mesh((n, 1), (\"x\", \"y\"))\n",
    "sharding = jax.sharding.NamedSharding(mesh, P(\"x\", \"y\"))\n",
    "print(sharding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_sharded = jax.device_put(arr, sharding)\n",
    "\n",
    "print(arr_sharded)\n",
    "jax.debug.visualize_array_sharding(arr_sharded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use JIT to let the XLA compilers in JAX perform the optimal load management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def f_contract(x):\n",
    "    return x.sum(axis=0)\n",
    "\n",
    "\n",
    "result = f_contract(arr_sharded)\n",
    "jax.debug.visualize_array_sharding(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo of vmap -- automatic vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jnp.array([1.0, 4.0, 0.5])\n",
    "b = jnp.arange(5, 10, dtype=jnp.float32)\n",
    "\n",
    "\n",
    "def weighted_mean(a, b):\n",
    "    output = []\n",
    "    for idx in range(1, b.shape[0] - 1):\n",
    "        output.append(jnp.mean(a + b[idx - 1 : idx + 2]))\n",
    "    return jnp.array(output)\n",
    "\n",
    "\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"b shape: {b.shape}\")\n",
    "output = weighted_mean(a, b)\n",
    "print(f\"output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's include the batch dim to the inputs\n",
    "batch_size = 8\n",
    "batched_a = jnp.stack([a] * batch_size)\n",
    "batched_b = jnp.stack([b] * batch_size)\n",
    "print(f\"batched_a shape: {batched_a.shape}\")\n",
    "print(f\"batched_b shape: {batched_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_output = jax.vmap(weighted_mean)(batched_a, batched_b)\n",
    "print(f\"batched output shape: {batched_output.shape}\")\n",
    "print(f\"batched output:\")\n",
    "print(batched_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compare the runtimes\n",
    "import time\n",
    "\n",
    "n = [1000, 2000, 4000, 8000, 16000, 32000, 64000]\n",
    "time_loop = []\n",
    "time_vmap = []\n",
    "for iters in n:\n",
    "    start = time.time()\n",
    "    for i in range(iters):\n",
    "        weighted_mean(a, b)\n",
    "    time_loop.append(time.time() - start)\n",
    "\n",
    "    batch_size = iters\n",
    "    batched_a = jnp.stack([a] * batch_size)\n",
    "    batched_b = jnp.stack([b] * batch_size)\n",
    "    start = time.time()\n",
    "    jax.vmap(weighted_mean)(batched_a, batched_b)\n",
    "    time_vmap.append(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.plot(n, time_loop, label=\"for loop\", alpha=0.5, c=\"firebrick\")\n",
    "plt.scatter(n, time_loop, c=\"firebrick\")\n",
    "plt.plot(n, time_vmap, label=\"vmap\", alpha=0.5, c=\"cornflowerblue\")\n",
    "plt.scatter(n, time_vmap, c=\"cornflowerblue\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"number of function calls\", fontsize=20)\n",
    "plt.ylabel(\"time (s)\", fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
